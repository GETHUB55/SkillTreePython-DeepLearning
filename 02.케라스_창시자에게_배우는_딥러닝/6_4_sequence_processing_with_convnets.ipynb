{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yebiny/SkillTreePython-DeepLearning/blob/main/02.%EC%BC%80%EB%9D%BC%EC%8A%A4_%EC%B0%BD%EC%8B%9C%EC%9E%90%EC%97%90%EA%B2%8C_%EB%B0%B0%EC%9A%B0%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D/6_4_sequence_processing_with_convnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 세팅\n",
        "---"
      ],
      "metadata": {
        "id": "16m7QEsKlcQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "! git clone https://github.com/yebiny/SkillTreePython-DeepLearning\n",
        "```"
      ],
      "metadata": {
        "id": "r6RjNGnQY3wc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqjonRF6KbGY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "import sys\n",
        "sys.path.append('/content/SkillTreePython-DeepLearning/scripts')\n",
        "from import_lib import *\n",
        "from plot_result import *\n",
        "```"
      ],
      "metadata": {
        "id": "iDliBVhLlYiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "InMFlAq4Xwge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-vYBogEYVEf"
      },
      "source": [
        "# 컨브넷을 사용한 시퀀스 처리\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 6장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
        "\n",
        "\n",
        "## 1D 컨브넷 구현\n",
        "\n",
        "케라스에서 1D 컨브넷은 `Conv1D` 층을 사용하여 구현합니다. `Conv1D`는 `Conv2D`와 인터페이스가 비슷합니다. `(samples, time, features)` 크기의 3D 텐서를 입력받고 비슷한 형태의 3D 텐서를 반환합니다. 합성곱 윈도우는 시간 축의 1D 윈도우입니다. 즉, 입력 텐서의 두 번째 축입니다.\n",
        "\n",
        "간단한 두 개 층으로 된 1D 컨브넷을 만들어 익숙한 IMDB 감성 분류 문제에 적용해 보죠.\n",
        "\n",
        "기억을 되살리기 위해 데이터를 로드하고 전처리하는 코드를 다시 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5SQypsoYVEg"
      },
      "outputs": [],
      "source": [
        "max_features = 10000  # 특성으로 사용할 단어의 수\n",
        "max_len = 500  # 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용합니다)\n",
        "\n",
        "imdb = tf.keras.datasets.imdb\n",
        "print('데이터 로드...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), '훈련 시퀀스')\n",
        "print(len(x_test), '테스트 시퀀스')\n",
        "\n",
        "print('시퀀스 패딩 (samples x time)')\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "print('x_train 크기:', x_train.shape)\n",
        "print('x_test 크기:', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ZzgHdlYVEh"
      },
      "source": [
        "1D 컨브넷은 5장에서 사용한 2D 컨브넷과 비슷한 방식으로 구성합니다. `Conv1D`와 `MaxPooling1D` 층을 쌓고 전역 풀링 층이나 `Flatten` 층으로 마칩니다. 이 구조는 3D 입력을 2D 출력으로 바꾸므로 분류나 회귀를 위해 모델에 하나 이상의 `Dense` 층을 추가할 수 있습니다.\n",
        "\n",
        "한 가지 다른 점은 1D 컨브넷에 큰 합성곱 윈도우를 사용할 수 있다는 것입니다. 2D 합성곱 층에서 3 × 3 합성곱 윈도우는 3 × 3 = 9 특성을 고려합니다. 하지만 1D 합성곱 층에서 크기 3인 합성곱 윈도우는 3개의 특성만 고려합니다. 그래서 1D 합성곱에 크기 7이나 9의 윈도우를 사용할 수 있습니다.\n",
        "\n",
        "다음은 IMDB 데이터셋을 위한 1D 컨브넷의 예입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgCE247VYVEi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h3UU5eRYVEi"
      },
      "source": [
        "그림 6-27과 6-28은 훈련과 검증 결과를 보여줍니다. 검증 정확도는 LSTM보다 조금 낮지만 CPU나 GPU에서 더 빠르게 실행됩니다(속도 향상은 환경에 따라 많이 다릅니다). 여기에서 적절한 에포크 수(4개)로 모델을 다시 훈련하고 테스트 세트에서 확인할 수 있습니다. 이 예는 단어 수준의 감성 분류 작업에 순환 네트워크를 대신하여 빠르고 경제적인 1D 컨브넷을 사용할 수 있음을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwQcgStyYVEk"
      },
      "source": [
        "## CNN과 RNN을 연결하여 긴 시퀀스를 처리하기\n",
        "\n",
        "1D 컨브넷이 입력 패치를 독립적으로 처리하기 때문에 RNN과 달리 (합성곱 윈도우 크기의 범위를 넘어선) 타임스텝의 순서에 민감하지 않습니다. 물론 장기간 패턴을 인식하기 위해 많은 합성곱 층과 풀링 층을 쌓을 수 있습니다. 상위 층은 원본 입력에서 긴 범위를 보게 될 것입니다. 이런 방법은 순서를 감지하기엔 부족합니다. 온도 예측 문제에 1D 컨브넷을 적용하여 이를 확인해 보겠습니다. 이 문제는 순서를 감지해야 좋은 예측을 만들어 낼 수 있습니다. 다음은 이전에 정의한 float_data, train_gen, val_gen, val_steps를 다시 사용합니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1AoQ3LlYVEm"
      },
      "source": [
        "이 기법이 연구 논문이나 실전 애플리케이션에 자주 등장하지는 않습니다. 아마도 널리 알려지지 않았기 때문일 것입니다. 이 방법은 효과적이므로 많이 사용되기를 바랍니다. 온도 예측 문제에 적용해 보죠. 이 전략은 훨씬 긴 시퀀스를 다룰 수 있으므로 더 오래전 데이터를 바라보거나(데이터 제너레이터의 `lookback` 매개변수를 증가시킵니다), 시계열 데이터를 더 촘촘히 바라볼 수 있습니다(제너레이터의 `step` 매개변수를 감소시킵니다). 여기서는 그냥 `step`을 절반으로 줄여서 사용하겠습니다. 온도 데이터가 30분마다 1 포인트씩 샘플링되기 때문에 결과 시계열 데이터는 두 배로 길어집니다. 앞서 정의한 제너레이터 함수를 다시 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnL6DVjTYVEn"
      },
      "source": [
        "이 모델은 두 개의 `Conv1D` 층 다음에 `GRU` 층을 놓았습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqI8oWI6YVEn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcUywmIYVEo"
      },
      "source": [
        "검증 손실로 비교해 보면 이 설정은 규제가 있는 GRU 모델만큼 좋지는 않습니다. 하지만 훨씬 빠르기 때문에 데이터를 두 배 더 많이 처리할 수 있습니다. 여기서는 큰 도움이 안 되었지만 다른 데이터셋에서는 중요할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnuZYu7YVEo"
      },
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이번 절에서 배운 것들입니다.\n",
        "\n",
        "* 2D 컨브넷이 2D 공간의 시각적 패턴을 잘 처리하는 것과 같이 1D 컨브넷은 시간에 따른 패턴을 잘 처리합니다. 1D 컨브넷은 특정 자연어 처리 같은 일부 문제에 RNN을 대신할 수 있는 빠른 모델입니다.\n",
        "* 전형적으로 1D 컨브넷은 컴퓨터 비전 분야의 2D 컨브넷과 비슷하게 구성합니다. `Conv1D` 층과 `Max-Pooling1D` 층을 쌓고 마지막에 전역 풀링 연산이나 `Flatten` 층을 둡니다.\n",
        "* RNN으로 아주 긴 시퀀스를 처리하려면 계산 비용이 많이 듭니다. 1D 컨브넷은 비용이 적게 듭니다. 따라서 1D 컨브넷을 RNN 이전의 전처리 단계로 사용하는 것은 좋은 생각입니다. 시퀀스 길이를 줄이고 RNN이 처리할 유용한 표현을 추출해 줄 것입니다.\n",
        "\n",
        "유용하고 중요한 개념이지만 여기서 다루지 않은 것은 팽창 커널을 사용한 1D 합성곱입니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mAIj-EXewBjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시계열 데이터 분석\n",
        "---"
      ],
      "metadata": {
        "id": "BiCJuR7ywB4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gilbutITbook/006975.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPM8ktY_wDXG",
        "outputId": "d8830814-b9c4-4d7d-cbc4-ab28fd5afe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '006975'...\n",
            "remote: Enumerating objects: 102534, done.\u001b[K\n",
            "remote: Total 102534 (delta 0), reused 0 (delta 0), pack-reused 102534\u001b[K\n",
            "Receiving objects: 100% (102534/102534), 202.75 MiB | 26.10 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (104042/104042), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/006975/datasets/jena_climate/'\n",
        "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
        "\n",
        "f = open(fname)\n",
        "data = f.read()\n",
        "f.close()\n",
        "\n",
        "lines = data.split('\\n')\n",
        "header = lines[0].split(',')\n",
        "lines = lines[1:]\n",
        "\n",
        "print(header)\n",
        "print(len(lines))\n",
        "\n",
        "float_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(',')[1:]]\n",
        "    float_data[i, :] = values\n",
        "\n",
        "mean = float_data[:200000].mean(axis=0)\n",
        "float_data -= mean\n",
        "std = float_data[:200000].std(axis=0)\n",
        "float_data /= std\n",
        "\n",
        "\n",
        "def generator(data, lookback, delay, min_index, max_index,\n",
        "              shuffle=False, batch_size=128, step=6):\n",
        "    if max_index is None:\n",
        "        max_index = len(data) - delay - 1\n",
        "    i = min_index + lookback\n",
        "    while 1:\n",
        "        if shuffle:\n",
        "            rows = np.random.randint(\n",
        "                min_index + lookback, max_index, size=batch_size)\n",
        "        else:\n",
        "            if i + batch_size >= max_index:\n",
        "                i = min_index + lookback\n",
        "            rows = np.arange(i, min(i + batch_size, max_index))\n",
        "            i += len(rows)\n",
        "\n",
        "        samples = np.zeros((len(rows),\n",
        "                           lookback // step,\n",
        "                           data.shape[-1]))\n",
        "        targets = np.zeros((len(rows),))\n",
        "        for j, row in enumerate(rows):\n",
        "            indices = range(rows[j] - lookback, rows[j], step)\n",
        "            samples[j] = data[indices]\n",
        "            targets[j] = data[rows[j] + delay][1]\n",
        "        yield samples, targets\n",
        "\n",
        "lookback = 1440\n",
        "step = 6\n",
        "delay = 144\n",
        "batch_size = 128\n",
        "\n",
        "train_gen = generator(float_data,\n",
        "                      lookback=lookback,\n",
        "                      delay=delay,\n",
        "                      min_index=0,\n",
        "                      max_index=200000,\n",
        "                      shuffle=True,\n",
        "                      step=step, \n",
        "                      batch_size=batch_size)\n",
        "val_gen = generator(float_data,\n",
        "                    lookback=lookback,\n",
        "                    delay=delay,\n",
        "                    min_index=200001,\n",
        "                    max_index=300000,\n",
        "                    step=step,\n",
        "                    batch_size=batch_size)\n",
        "test_gen = generator(float_data,\n",
        "                     lookback=lookback,\n",
        "                     delay=delay,\n",
        "                     min_index=300001,\n",
        "                     max_index=None,\n",
        "                     step=step,\n",
        "                     batch_size=batch_size)\n",
        "\n",
        "# 전체 검증 세트를 순회하기 위해 val_gen에서 추출할 횟수\n",
        "val_steps = (300000 - 200001 - lookback) // batch_size\n",
        "\n",
        "# 전체 테스트 세트를 순회하기 위해 test_gen에서 추출할 횟수\n",
        "test_steps = (len(float_data) - 300001 - lookback) // batch_size\n",
        "\n",
        "for samples, targets in train_gen:\n",
        "  print(samples.shape, targets.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "9gAHwgljwTPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_PjHrQG-whvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hRm4rwUFwvQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B0tj_fosxLZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "6.4-sequence-processing-with-convnets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}